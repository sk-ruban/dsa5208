{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sk-ruban/dsa5208/blob/main/kernel_ridge_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyenq7obG4le"
      },
      "source": [
        "We will split the notebook into the following five sections:\n",
        "1. Data preparation\n",
        "2. Set up MPI processes\n",
        "3. Applying distributed kernel ridge regression\n",
        "4. Obtaining predicted median value using kernel function\n",
        "5. Evaluating model performance\n",
        "6. Cross Validation / Model Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "# !pip3 install wheel\n",
        "# !pip3 install mpi4py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lkMqw3GRHz74"
      },
      "outputs": [],
      "source": [
        "# Import Dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from mpi4py import MPI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ge6TJIcHaRp"
      },
      "source": [
        "## **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "HhYbDDPvG8FK",
        "outputId": "19131633-5f98-4a81-902e-6bdba9f12f55"
      },
      "outputs": [],
      "source": [
        "# Import Data\n",
        "df = pd.read_csv('data/housing_short.tsv', sep='\\t', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.columns = ['longitude', 'latitude', 'housingMedianAge', 'totalRooms',\n",
        "              'totalBedrooms', 'population', 'households', 'medianIncome',\n",
        "              'oceanProximity', 'medianHouseValue']\n",
        "\n",
        "features = ['longitude', 'latitude', 'housingMedianAge', 'totalRooms',\n",
        "              'totalBedrooms', 'population', 'households', 'medianIncome',\n",
        "              'oceanProximity']\n",
        "\n",
        "# print(df.info())\n",
        "# print(\"\\nFirst few rows:\")\n",
        "# print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KtocUfNLH-kh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   longitude  latitude  housingMedianAge  totalRooms  totalBedrooms  \\\n",
            "0  -1.076704  0.743879          0.761259   -0.834767      -1.012490   \n",
            "1  -1.071483  0.733996         -0.777695    2.611221       1.598957   \n",
            "2  -1.081925  0.729055          1.607684   -0.509506      -0.849441   \n",
            "3  -1.087146  0.729055          1.607684   -0.616449      -0.729160   \n",
            "4  -1.087146  0.729055          1.607684   -0.420849      -0.608878   \n",
            "\n",
            "   population  households  medianIncome  oceanProximity  medianHouseValue  \n",
            "0   -1.060704   -0.996316      2.647538         1.55863            452600  \n",
            "1    1.127364    1.920014      2.634566         1.55863            358500  \n",
            "2   -0.877575   -0.849347      2.065575         1.55863            352100  \n",
            "3   -0.812323   -0.728314      1.185764         1.55863            341300  \n",
            "4   -0.804955   -0.613044      0.206434         1.55863            342200  \n"
          ]
        }
      ],
      "source": [
        "#Normalize Data\n",
        "scaler = StandardScaler()\n",
        "df[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set shape: (3500, 9)\n",
            "Test set shape: (1500, 9)\n"
          ]
        }
      ],
      "source": [
        "# Split Data\n",
        "X = df[features]\n",
        "y = df['medianHouseValue']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Test set shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Set up MPI Processes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.Get_rank()\n",
        "size = comm.Get_size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data according to process\n",
        "\n",
        "chunk_size = len(X_train) // size\n",
        "start = rank * chunk_size\n",
        "end = start + chunk_size if rank < size - 1 else len(X_train)\n",
        "X_chunk = X_train[start:end]\n",
        "y_chunk = y_train[start:end]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5r6WMHeofS_"
      },
      "source": [
        "## **Applying Kernel Ridge Regression**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "74ZsY2geomwH"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'Series' object has no attribute 'reshape'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/_k/hgt2zf0s18x5lvv1gwk899pc0000gn/T/ipykernel_30238/1956659803.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompute_gaussian_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Add up all the computed rows to get matrix K\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m  \u001b[0;31m# TUNE PARAMETER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mlocal_K\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_local_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAllreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_K\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMPI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/var/folders/_k/hgt2zf0s18x5lvv1gwk899pc0000gn/T/ipykernel_30238/1956659803.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X_chunk, X_full, sigma)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_local_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompute_gaussian_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/var/folders/_k/hgt2zf0s18x5lvv1gwk899pc0000gn/T/ipykernel_30238/1956659803.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X1, X2, sigma)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_gaussian_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdists\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m                                                \u001b[0;31m# exp( - dists / 2.sigma )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'reshape'"
          ]
        }
      ],
      "source": [
        "# Define Kernel Computation Function\n",
        "def compute_gaussian_kernel(X1, X2, sigma):\n",
        "    dists = np.sum(X1**2, axis=1).reshape(-1, 1) + np.sum(X2**2, axis=1) - 2 * np.dot(X1, X2.T)\n",
        "    return np.exp(-dists / (2 * sigma ** 2))                                                # exp( - dists / 2.sigma )\n",
        "\n",
        "\n",
        "# Apply Kernel Computation Function to all split data\n",
        "def compute_local_kernel(X_chunk, X_full, sigma):\n",
        "    return compute_gaussian_kernel(X_chunk, X_full, sigma)\n",
        "\n",
        "# Add up all the computed rows to get matrix K\n",
        "sigma = 1.0  # TUNE PARAMETER\n",
        "local_K = compute_local_kernel(X_chunk, X_train, sigma)\n",
        "K = np.zeros((len(X_train), len(X_train)))\n",
        "comm.Allreduce(local_K, K, op=MPI.SUM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Solve for matrix A which is defined as K + lambda I\n",
        "lambda_ = 1.0  \n",
        "A = K + lambda_ * np.eye(K.shape[0])\n",
        "\n",
        "# Solve for alpha, using A(alpha) = y, and the Conjugate Gradient Method\n",
        "def conjugate_gradient(A, b, max_iter=1000, tol=1e-6):\n",
        "    x = np.zeros_like(b)\n",
        "    r = b - A @ x\n",
        "    p = r.copy()\n",
        "    r_norm_sq = np.dot(r, r)\n",
        "    \n",
        "    for _ in range(max_iter):\n",
        "        Ap = A @ p\n",
        "        alpha = r_norm_sq / np.dot(p, Ap)\n",
        "        x += alpha * p\n",
        "        r -= alpha * Ap\n",
        "        r_norm_sq_new = np.dot(r, r)\n",
        "        if np.sqrt(r_norm_sq_new) < tol:\n",
        "            break\n",
        "        beta = r_norm_sq_new / r_norm_sq\n",
        "        p = r + beta * p\n",
        "        r_norm_sq = r_norm_sq_new\n",
        "    \n",
        "    return x\n",
        "\n",
        "alpha = conjugate_gradient(A, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prediction function\n",
        "def predict(X_new):\n",
        "    K_new = compute_gaussian_kernel(X_new, X_train, sigma)\n",
        "    return K_new @ alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if rank == 0:\n",
        "    y_train_pred = predict(X_train)\n",
        "    y_test_pred = predict(X_test)\n",
        "    \n",
        "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "    \n",
        "    print(f\"Train RMSE: ${train_rmse:.2f}\")\n",
        "    print(f\"Test RMSE: ${test_rmse:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters for linear kernel: {'alpha': 10}\n",
            "linear kernel - Train RMSE: $188273.19\n",
            "linear kernel - Test RMSE: $187795.50\n",
            "\n",
            "Best parameters for rbf kernel: {'alpha': 0.1, 'gamma': 0.1}\n",
            "rbf kernel - Train RMSE: $43552.43\n",
            "rbf kernel - Test RMSE: $49753.43\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Solve with SKLEARN\n",
        "\"\"\"\n",
        "Best parameters for linear kernel: {'alpha': 10}\n",
        "linear kernel - Train RMSE: $188273.19\n",
        "linear kernel - Test RMSE: $187795.50\n",
        "\n",
        "Best parameters for rbf kernel: {'alpha': 0.1, 'gamma': 0.1}\n",
        "rbf kernel - Train RMSE: $43552.43\n",
        "rbf kernel - Test RMSE: $49753.43\n",
        "\"\"\"\n",
        "\n",
        "def train_and_evaluate(kernel, X_train, y_train, X_test, y_test):\n",
        "    if kernel == 'linear':\n",
        "        param_grid = {'alpha': [0.1, 1, 10]}\n",
        "    else:\n",
        "        param_grid = {'alpha': [0.1, 1, 10], 'gamma': [0.1, 1, 10]}\n",
        "    \n",
        "    krr = KernelRidge(kernel=kernel)\n",
        "    grid_search = GridSearchCV(krr, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    \n",
        "    best_params = grid_search.best_params_\n",
        "    print(f\"Best parameters for {kernel} kernel:\", best_params)\n",
        "    \n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_train_pred = best_model.predict(X_train)\n",
        "    y_test_pred = best_model.predict(X_test)\n",
        "    \n",
        "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "    \n",
        "    print(f\"{kernel} kernel - Train RMSE: ${train_rmse:.2f}\")\n",
        "    print(f\"{kernel} kernel - Test RMSE: ${test_rmse:.2f}\")\n",
        "    print()\n",
        "\n",
        "# Try different kernels\n",
        "for kernel in ['linear', 'rbf']:\n",
        "    train_and_evaluate(kernel, X_train, y_train, X_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
